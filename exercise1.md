
# âœ… Follow-up Exercise: Improving Fine-Tuning and Measuring Impact

"""
ğŸš€ Now that you've completed a basic fine-tuning pass, let's expand and evaluate how much the model improves.

### ğŸ“š Instructions:
1. **Expand the dataset** to include more diverse examples (e.g., 8â€“10 sentences).
2. **Train for 3 epochs** instead of 1 to give the model more time to learn.
3. **Evaluate the model before and after training** using multiple test sentences.
4. **Compare predictions and confidence scores.**

---

### ğŸ“ Example Expanded Dataset:

```python
data = {
    "text": [
        "This product is awful.",
        "I hated this movie. Waste of time.",
        "Terrible customer service experience.",
        "I will never buy this again.",
        "This is a fantastic product!",
        "Absolutely loved the performance.",
        "Great quality and easy to use.",
        "Highly recommended!"
    ],
    "label": [0, 0, 0, 0, 1, 1, 1, 1]
}
```

---

### ğŸ” Suggested Test Inputs:
Use these both *before* and *after* fine-tuning:

```python
test_sentences = [
    "This is terrible.",
    "What a wonderful experience!",
    "I would not recommend this.",
    "Best thing Iâ€™ve bought this year!"
]
```

---

### ğŸ§  Your Task:
- Measure the modelâ€™s predictions (probabilities and sentiment) for each test sentence
- Present the results in a clear before/after comparison
- Interpret what the model has learned (or hasnâ€™t)

You can even make a chart or table if you're feeling adventurous!

Good luck â€” and remember: the more data you give your model, the smarter it gets. ğŸ˜‰
"""
